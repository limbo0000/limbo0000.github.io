<html>
    <head>
            <style type="text/css">
                /* Color scheme stolen from Sergey Karayev */
            
                a {
                  color: #1772d0;
                  text-decoration: none;
                }
            
                a:focus,
                a:hover {
                  color: #f09228;
                  text-decoration: none;
                }
            
                body,
                td,
                th,
                tr,
                p,
                a {
                  font-family: 'Lato', Verdana, Helvetica, sans-serif;
                  font-size: 15px
                }
            
                strong {
                  font-family: 'Lato', Verdana, Helvetica, sans-serif;
                  font-size: 15px;
                }
            
                heading {
                  font-family: 'Lato', Verdana, Helvetica, sans-serif;
                  font-size: 23px;
                }
            
                papertitle {
                  font-family: 'Lato', Verdana, Helvetica, sans-serif;
                  font-size: 15px;
                  font-weight: 700
                }
            
                name {
                  font-family: 'Lato', Verdana, Helvetica, sans-serif;
                  font-size: 33px;
                }
            
                .one {
                  width: 160px;
                  height: 160px;
                  position: relative;
                }
            
                .two {
                  width: 160px;
                  height: 160px;
                  position: absolute;
                  transition: opacity .2s ease-in-out;
                  -moz-transition: opacity .2s ease-in-out;
                  -webkit-transition: opacity .2s ease-in-out;
                }
            
                .fade {
                  transition: opacity .2s ease-in-out;
                  -moz-transition: opacity .2s ease-in-out;
                  -webkit-transition: opacity .2s ease-in-out;
                }
            
                span.highlight {
                  background-color: #ffffd0;
                }
              </style>
        <title>Ceyuan Yang's Homepage </title>
</head>
    <body><table border=0 width=980px align=center><tr><td>
    
        <td valign="top">

        <br>
        <table style="font-size: 11pt;" border=0 width=100%>
            <tr>

                <td>
                    <font face="helvetica, ariel, 'sans serif'" size="6"> 
                        <b>Ceyuan Yang</b><br><br><br>
                    </font>
                    <font face="helvetica, ariel, 'sans serif'" size="4"> 
                        PhD Student<br>
                        Department of Information Engineering<br>
                        The Chinese University of Hong Kong<br><br>
                        <a href="mailto:yc019@ie.cuhk.edu.hk">E-mail</a> &nbsp/&nbsp
                        <a href="https://scholar.google.com/citations?user=Rfj4jWoAAAAJ&hl=zh-TW">Google Scholar</a> &nbsp/&nbsp
                        <a href="https://github.com/limbo0000"> Github </a> 
                    </font>
                </td>
                <td width = "30%">
                    <img width=250 src="images/me.jpg" border="0">
                        </td>
            </tr>
        </table> 


        <h2>Full Publications <small>[<a href="./index.html">Home</a>]</small> </h2>
        <font face="helvetica, ariel, 'sans serif'">

        <table style="font-size: 11pt;" border=0 width=100%>
            <tr>

                <td>
                    <font face="helvetica, ariel, 'sans serif'" size="4">
                        <a href="pub.html" class="btn btn-default" role="button">All by Year</a> &nbsp/&nbsp
                        <a href="rep_learning.html" class="btn btn-default" role="button">Representation Learning</a> &nbsp/&nbsp
                        <a href="video_understanding.html" class="btn btn-default" role="button">Video Understanding</a> &nbsp/&nbsp
                        <a href="gan.html" class="btn btn-default" role="button">Generative modeling</a> 
                    </font>
                </td>
            </tr>
        </table>

            <table cellspacing="17">

                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/insloc.png" border="0">
                            </td>
                    <td>
                    <strong>Instance Localization for Self-supervised Detection Pretraining,</strong>
                    <br>
                    <strong>Ceyuan Yang,</strong> <a href="https://scholar.google.com/citations?hl=en&user=lH4zgcIAAAAJ&view_op=list_works&sortby=pubdate">Zhirong Wu</a>, <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>, <a href="https://scholar.google.com/citations?user=c3PYmxUAAAAJ&hl=zh-TW">Stephen Lin</a>.
                    <br>
                    <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2021.
                    <br>
                    [<a href="https://arxiv.org/pdf/2102.08318.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/limbo0000/InstanceLoc"><font color="red" size="3">Code</font></a>]<p></p>
                    </td>
                </tr>

                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/gh_feat.png" border="0">
                            </td>
                    <td>
                    <strong>Generative Hierarchical Features from Synthesizing Images,</strong>
                    <br>
                    <a href="https://justimyhxu.github.io/academic.html">Yinghao Xu*</a>, <a href="https://shenyujun.github.io/">Yujun Shen*</a>, Jiapeng Zhu, <strong>Ceyuan Yang,</strong> <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>.
                    <br>
                    <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2021.
                    <br>
                    [<a href="https://arxiv.org/pdf/2007.10379.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/genforce/ghfeat"><font color="red" size="3">Code</font></a>]
                    <br>
                    </td>
                </tr>


                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/iclr_2020.jpg" border="0">
                            </td>
                    <td>
                    <strong>Semantic Hierarchy Emerges in Deep Generative Representations for Scene Synthesis,</strong>
                    <br>
                    <strong>Ceyuan Yang*,</strong> <a href="https://shenyujun.github.io/">Yujun Shen*</a>, <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>.
                    <br>
                    <em>International Journal of Computer Vision </em> (<b>IJCV</b>), 2020.
                    <br>
                    [<a href="https://arxiv.org/pdf/1911.09267.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://genforce.github.io/higan/"><font color="red" size="3">Webpage</font></a>][<a href="https://github.com/genforce/higan"><font color="red" size="3">Code</font></a>][<a href="http://visual.cs.brown.edu/aicc2020/pubs/AICCW2020_ExtendedAbstract_YangEtAl_SemanticHierarchyEmergesInDeepGenerativeRepresentationsForSceneSynthesis.pdf"><font color="red" size="3">Workshop version</font></a>]<p></p>
                    </td>
                </tr>



                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/interfacegan.jpg" border="0">
                            </td>
                    <td>
                    <strong>InterFaceGAN: Interpreting the Disentangled Face Representation Learned by GANs,</strong>
                    <br>
                    <a href="https://shenyujun.github.io/">Yujun Shen</a>, <strong>Ceyuan Yang,</strong> <a href="https://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>, <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>.
                    <br>
                    <em>IEEE Trans. on Pattern Analysis and Machine Intelligence </em>(<b>T-PAMI</b>), 2020.
                    <br>
                    [<a href="https://arxiv.org/pdf/2005.09635.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/genforce/interfacegan"><font color="red" size="3">Code</font></a>][<a href="https://genforce.github.io/interfacegan/"><font color="red" size="3">Webpage</font></a>]
                    <br>
                    </td>
                </tr>

                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/eccv_2020.png" border="0">
                            </td>
                    <td>
                    <strong>Learning Motion Priors for Efficient Video Object Detection,</strong> 
                    <br>
                    <a href="https://jiangzhengkai.github.io/">Zhengkai Jiang</a>, <a href="http://liuyu.us/">Yu Liu</a>, <strong>Ceyuan Yang</strong>, Jihao Liu, Qian Zhang, Shiming Xiang, Chunhong Pan. 
                    <br>
                    <em>IEEE European Conference on Computer Vision</em> (<b>ECCV</b>), 2020. <br>
                    [<a href="https://arxiv.org/pdf/1911.05253.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/jiangzhengkai/lsts"><font color="red" size="3">Code</font></a>]
                    </td>
                </tr>
                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/landmark.png" border="0">
                            </td>
                    <td>
                    <strong>Unsupervised Landmark Learning from Unpaired Data,</strong> 
                    <br>
                    <a href="https://justimyhxu.github.io/academic.html">Yinghao Xu*</a>, <strong>Ceyuan Yang*,</strong> <a href="https://liuziwei7.github.io/">Ziwei Liu</a>, <a href="http://daibo.info/">Bo Dai</a>, <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>. 
                    <br>
                    <em>arxiv pre-print</em>, 2020.
                    <br>
                    [<a href="https://arxiv.org/pdf/2007.01053.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/justimyhxu/ULTRA"><font color="red" size="3">Code</font></a>]
                    <br>
                    </td>
                </tr>


                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/vthcl.png" border="0">
                            </td>
                    <td>
                    <strong>Video Representation Learning with Visual Tempo Consistency,</strong> 
                    <br>
                    <strong>Ceyuan Yang,</strong> <a href="https://justimyhxu.github.io/academic.html">Yinghao Xu</a>, <a href="http://daibo.info/">Bo Dai</a>, <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>. 
                    <br>
                    <em>arxiv pre-print</em>, 2020.
                    <br>
                    [<a href="https://arxiv.org/pdf/2006.15489.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/decisionforce/VTHCL"><font color="red" size="3">Code</font></a>]
                    <br>
                    </td>
                </tr>

                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/cvpr2020.png" border="0">
                            </td>
                    <td>
                    <strong>Temporal Pyramid Network for Action Recognition,</strong> 
                    <br>
                    <strong>Ceyuan Yang*,</strong> <a href="https://justimyhxu.github.io/academic.html">Yinghao Xu*</a>, <a href="http://shijianping.me/">Jianping Shi</a>, <a href="http://daibo.info/">Bo Dai</a>, <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>. 
                    <br>
                    <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2020.
                    <br>
                    [<a href="https://arxiv.org/pdf/2004.03548.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://decisionforce.github.io/TPN/"><font color="red" size="3">Webpage</font></a>][<a href="https://github.com/decisionforce/TPN"><font color="red" size="3">Code</font></a>]
                    <br>
                    </td>
                </tr>
                <tr>
                    <td width="35%">
                        <img width="320" height="160" src="images/cvpr2019.png" border="0">
                            </td>
                    <td>
                    <strong>Adapting Object Detectors via Selective Cross-Domain Alignment,</strong> 
                    <br>
                    <a href="https://xingezhu.me/aboutme.html">Xinge Zhu</a>, Jiangmiao Pang, <strong>Ceyuan Yang,</strong> <a href="http://shijianping.me/">Jianping Shi</a>, <a href="http://dahua.me/">Dahua Lin</a>. 
                    <br>
                    <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2019.
                    <br>
                    [<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Adapting_Object_Detectors_via_Selective_Cross-Domain_Alignment_CVPR_2019_paper.pdf"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/WERush/SCDA"><font color="red" size="3">Code</font></a>]<p></p>
                    </td>
                </tr>
                <tr>
                        <td width="35%">
                            <img width="320" height="160" src="images/eccv2018_2.png" border="0">
                                </td>
                        <td>
                                <strong>Pose Guided Human Video Generation,</strong>
                                <br>
                            <strong> Ceyuan Yang, </strong> <a href="https://wang-zhe.me/">Zhe Wang</a>, <a href="https://xingezhu.me/aboutme.html">Xinge Zhu</a>, <a href="https://scholar.google.com/citations?user=QZ-JKOUAAAAJ&hl=en">Chen Huang</a>, <a href="http://shijianping.me/">Jianping Shi</a>, <a href="http://dahua.me/">Dahua Lin</a>. 
                            <br>
                            <em>IEEE European Conference on Computer Vision</em> (<b>ECCV</b>), 2018. <br>
                         [<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ceyuan_Yang_Pose_Guided_Human_ECCV_2018_paper.pdf"><font color="red" size="3">Paper</font></a>]<p></p>

                        </td>
                    </tr>
                    
                    <tr>
                            <td width="35%">
                                <img width="320" height="160" src="images/eccv2018_1.png" border="0">
                                    </td>
                            <td>
                                    <strong>Penalizing Top Performers: Conservative Loss for Semantic Segmentation Adaptation,</strong>
                                    <br>
                            <a href="https://xingezhu.me/aboutme.html">Xinge Zhu</a>, <a href="https://scholar.google.com/citations?user=i35tdbMAAAAJ&hl=zh-TW">Hui Zhou</a>, <strong>Ceyuan Yang,</strong> <a href="http://shijianping.me/">Jianping Shi</a>, <a href="http://dahua.me/">Dahua Lin</a>. 
                            <br>
                            <em>IEEE European Conference on Computer Vision</em> (<b>ECCV</b>), 2018.
                            <br>
                            [<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Xinge_Zhu_Penalizing_Top_Performers_ECCV_2018_paper.pdf"><font color="red" size="3">Paper</font></a>] <p></p>
                            </td>
                        </tr>
                        <tr>
                                <td width="35%">
                                    <img width="320" height="160" src="images/tgrs.jpg" border="0">
                                        </td>
                                <td>
                                        <strong>Remote Sensing Image Scene Classification via Learning Discriminative CNNs, </strong> 
                                        <br>
                                <a href="https://scholar.google.com/citations?user=dw1n0vIAAAAJ&hl=zh-TW">Gong Cheng</a>, <strong>Ceyuan Yang,</strong> Xiwen Yao, Lei Guo, Junwei Han. 
                                <br>
                                <em>IEEE Trans. on Geoscience and Remote Sensing</em> (<b>TGRS</b>), 2018.
                                <br>
                                [<a href="http://ieeexplore.ieee.org/document/8252784/"><font color="red" size="3">Paper</font></a>][<a href="https://github.com/limbo0000/PairLoss"><font color="red" size="3">Code</font></a>]<p></p>
                                </td>
                            </tr>
            </table>
            </body>
</html>
